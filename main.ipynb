{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold,cross_validate\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import itertools\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('/home/pawblo/Desktop/studia/semestr3/Siwib/data/data/ae_retro_data.xlsx - Discretized.csv')\n",
    "df.replace(\"?\", np.nan, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts = df.isna().sum()\n",
    "\n",
    "\n",
    "nan_counts = nan_counts[nan_counts > 0]\n",
    "nan_counts_sorted = nan_counts.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "nan_counts_sorted.plot(kind='bar')\n",
    "plt.title('Number of NaN Values in Each Column (Sorted)')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of NaN Values')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['CORR_CATEGORY'] = df['CORR_CATEGORY'].map({'LONG': 1, 'ADMIT': 1, 'SHORT': 0})\n",
    "\n",
    "df['CORR_CATEGORY'].value_counts(), df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop('CORR_CATEGORY', axis=1)\n",
    "y = df['CORR_CATEGORY']\n",
    "\n",
    "\n",
    "missing_values_count = X.isnull().sum()\n",
    "\n",
    "\n",
    "missing_values_count_sorted = missing_values_count.sort_values(ascending=False)\n",
    "\n",
    "columns_to_drop = missing_values_count_sorted.head(1).index\n",
    "\n",
    "\n",
    "# X = X.drop(columns=columns_to_drop)\n",
    "\n",
    "# # X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "# X_filled = imp.fit_transform(X)\n",
    "# # imputer = KNNImputer(n_neighbors=5)\n",
    "# # X_filled = imputer.fit_transform(X)\n",
    "\n",
    "# X = pd.DataFrame(X_filled, columns=X.columns)\n",
    "# categorical_cols = X.columns\n",
    "# categorical_cols\n",
    "# print(X.shape)\n",
    "# categorical_transformer = ColumnTransformer(transformers=[\n",
    "#     ('cat', OneHotEncoder(), categorical_cols)\n",
    "# ], remainder='passthrough') \n",
    "# X = categorical_transformer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "encoder = OrdinalEncoder()\n",
    "X_encoded = encoder.fit_transform(X.apply(lambda x: x.astype(str)))\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "X_imputed = imputer.fit_transform(X_encoded)\n",
    "\n",
    "X = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=12, whiten=True)\n",
    "X_pca = pca.fit_transform(X_imputed)\n",
    "\n",
    "X = pd.DataFrame(X_pca, columns=[f\"PC{i+1}\" for i in range(X_pca.shape[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_prediction(y_pred_proba: np.ndarray, medium_risk: float, high_risk: float):\n",
    "    return np.array([0 if response < medium_risk else 1 if response >= high_risk else np.nan for response in y_pred_proba])\n",
    "def calculate_rates(\n",
    "    y: np.ndarray, y_pred: np.ndarray, positives: float, negatives: float\n",
    ") -> tuple[float, float, float, float]:\n",
    "    tn, tp, fn, fp = confusion_matrix(y, y_pred).ravel()\n",
    "    tpr = tp / (tp + fn)  \n",
    "    fnr = fn / (fn + tp)  \n",
    "    fpr = fp / (fp + tn)  \n",
    "    tnr = tn / (tn + fp)  \n",
    "\n",
    "\n",
    "    return tpr, fnr, fpr, tnr\n",
    "def train_evaluate_classifier(classifier, X,y, name):\n",
    "    auroc_scores = []\n",
    "    auprc_scores = []\n",
    "    medium = []\n",
    "    high = []\n",
    "    positives = []\n",
    "    negatives = []\n",
    "    fnrs = []\n",
    "    fprs = []\n",
    "    for _ in range(3):\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random.randint(0,130))\n",
    "        \n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "           \n",
    "            X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train_fold, y_val_fold = y[train_index], y[test_index]\n",
    "            classifier.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = classifier.predict(X_val_fold)\n",
    "            auroc = roc_auc_score(y_val_fold, y_pred)\n",
    "            auprc = average_precision_score(y_val_fold, y_pred)\n",
    "            auroc_scores.append(auroc)\n",
    "            auprc_scores.append(auprc)\n",
    "            y_pred_proba = classifier.predict_proba(X_val_fold)[:,1]\n",
    "            y_pred_proba_train = classifier.predict_proba(X_train_fold)[:, 1]\n",
    "            fpr, tpr, thresholds = roc_curve(y_train_fold, y_pred_proba_train)\n",
    "            medium_risk = thresholds[tpr >= 0.99][0]\n",
    "            high_risk = thresholds[fpr >= (1 - 0.9)][0]\n",
    "            predicted = make_prediction(y_pred_proba, medium_risk, high_risk)\n",
    "            medium.append(medium_risk)\n",
    "            high.append(high_risk)\n",
    "            positive = np.sum(predicted == 1)\n",
    "            negative = np.sum(predicted == 0)\n",
    "            unknown = np.sum(np.isnan(predicted))\n",
    "            number_of_samples: int = len(X_val_fold)\n",
    "            positives.append(positive / number_of_samples)\n",
    "            negatives.append(negative / number_of_samples)\n",
    "            mask = ~np.isnan(predicted)\n",
    "            tpr, fnr, fpr, tnr = calculate_rates(y_val_fold[mask], predicted[mask], positive, negative)\n",
    "            fnrs.append(fnr)\n",
    "            fprs.append(fpr)\n",
    "    return {\n",
    "            f\"{name}- aurocs\":np.mean(auroc_scores),\n",
    "            f\"{name}- auprcs\":np.mean(auprc_scores),\n",
    "            f\"{name}- positives\":np.mean(positives),\n",
    "            f\"{name}- negatives\":np.mean(negatives),\n",
    "            f\"{name}- fnrs\":np.mean(fnrs),\n",
    "            f\"{name}- fprs\":np.mean(fprs)\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "train_evaluate_classifier(classifier,X,y, \"base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(random_state=42)\n",
    "print(train_evaluate_classifier(classifier,X,y, \"target\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "def param_combinations(params):\n",
    "    keys, values = zip(*params.items())\n",
    "    for v in itertools.product(*values):\n",
    "        yield dict(zip(keys, v))\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in param_combinations(param_grid):\n",
    "    classifier = RandomForestClassifier(random_state=42, **params)\n",
    "    evaluation_results = train_evaluate_classifier(classifier, X, y, \"base\")\n",
    "    results.append({'params': params, 'evaluation_results': evaluation_results})\n",
    "\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_points=[]\n",
    "y_points=[]\n",
    "labels = []\n",
    "i=0\n",
    "for res in results:\n",
    "    x_points.append(res['evaluation_results']['base- aurocs']+res['evaluation_results']['base- auprcs'])\n",
    "    y_points.append(res['evaluation_results']['base- fnrs']+res['evaluation_results']['base- fprs'])\n",
    "    labels.append(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_points, y_points)\n",
    "for x in range(len(labels)):\n",
    "    plt.text(x_points[x], y_points[x], labels[x])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_target=results[20]\n",
    "classifier = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "result_base = train_evaluate_classifier(classifier,X,y, \"base\")\n",
    "result_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_example = pd.Series(y)\n",
    "\n",
    "class_counts = y_example.value_counts()\n",
    "\n",
    "plt.bar(class_counts.index, class_counts.values, color=['blue', 'orange'])\n",
    "plt.xlabel('Decision Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Decision Classes')\n",
    "plt.xticks(ticks=class_counts.index, labels=['Class 0', 'Class 1'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
